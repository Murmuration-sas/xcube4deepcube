{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "import zarr\n",
    "import xcube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- every dataset is in NetCDF format, can consist of multiple files, but should be in a single folder\n",
    "- datasets should already be in equirectangular lon-lat coordinate system\n",
    "- make sure that all static variables have a time dimension (use ds.expand_dims)\n",
    "- and add time_bnds attribute to them so they can be processed by the xcube default processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cams = xr.open_dataset('datasat_nc/CAMS.nc')\n",
    "lc100 = xr.open_dataset('datasat_nc/LC100_2019.nc')\n",
    "ndvi = xr.open_dataset('datasat_nc/NDVI.nc')\n",
    "swi = xr.open_dataset('datasat_nc/SWI.nc')\n",
    "thermal_mrt = xr.open_dataset('datasat_nc/thermal_mrt.nc')\n",
    "thermal_utci = xr.open_dataset('datasat_nc/thermal_utci.nc')\n",
    "astgtm = xr.open_dataset('datasat_nc/ASTGTM_no_time.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lon_array = np.linspace(-47,-42,300)\n",
    "target_lon = xr.DataArray(target_lon_array, dims=(\"lon\"), coords={\"lon\": target_lon_array})\n",
    "target_lon.attrs[\"standard_name\"] = \"lon\"\n",
    "target_lon.attrs[\"long_name\"] = \"longitude\"\n",
    "target_lon.attrs[\"units\"] = \"degrees_east\"\n",
    "\n",
    "target_lat_array = np.linspace(-6,-1,300)\n",
    "target_lat = xr.DataArray(target_lat_array, dims=(\"lat\"), coords={\"lat\": target_lat_array})\n",
    "target_lat.attrs[\"standard_name\"] = \"lat\"\n",
    "target_lat.attrs[\"long_name\"] = \"latitude\"\n",
    "target_lat.attrs[\"units\"] = \"degrees_north\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "lc100_interp = lc100.chunk().interp({'lon':target_lon, 'lat':target_lat},  method = 'linear')\n",
    "cams_interp = cams.chunk().interp({'lon':target_lon, 'lat':target_lat},  method = 'linear')\n",
    "ndvi_interp = ndvi.chunk().interp({'lon':target_lon, 'lat':target_lat},  method = 'linear')\n",
    "swi_interp = swi.chunk().interp({'lon':target_lon, 'lat':target_lat},  method = 'linear')\n",
    "thermal_mrt_interp = thermal_mrt.chunk().interp({'lon':target_lon, 'lat':target_lat},  method = 'linear')\n",
    "thermal_utci_interp = thermal_utci.chunk().interp({'lon':target_lon, 'lat':target_lat},  method = 'linear')\n",
    "astgtm_interp = astgtm.chunk().interp({'lon':target_lon, 'lat':target_lat},  method = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vars = {}\n",
    "\n",
    "# Land Cover\n",
    "output_vars['LC100'] = lc100_interp['LC100']\n",
    "\n",
    "# CAMS forecasting\n",
    "output_vars['CAMS_ch4'] = cams_interp['tc_ch4']\n",
    "output_vars['CAMS_no2'] = cams_interp['tcno2']\n",
    "output_vars['CAMS_no'] = cams_interp['tc_no']\n",
    "output_vars['CAMS_co3'] = cams_interp['gtco3']\n",
    "output_vars['CAMS_so2'] = cams_interp['tcso2']\n",
    "output_vars['CAMS_co'] = cams_interp['tcco']\n",
    "    \n",
    "# NDVI \n",
    "output_vars['NDVI'] = ndvi_interp['NDVI']\n",
    "output_vars['NDVI_unc'] = ndvi_interp['NDVI_unc']\n",
    "\n",
    "# SWI\n",
    "output_vars['SWI_001'] = swi_interp['SWI_001']\n",
    "output_vars['SWI_005'] = swi_interp['SWI_005']\n",
    "output_vars['SWI_010'] = swi_interp['SWI_010']\n",
    "output_vars['SWI_015'] = swi_interp['SWI_015']\n",
    "output_vars['SWI_020'] = swi_interp['SWI_020']\n",
    "output_vars['SWI_040'] = swi_interp['SWI_040']\n",
    "output_vars['SWI_060'] = swi_interp['SWI_060']\n",
    "output_vars['SWI_100'] = swi_interp['SWI_100']\n",
    "\n",
    "# Thermal MRT\n",
    "output_vars['THERMAL_MRT'] = thermal_mrt_interp['mrt']\n",
    "\n",
    "# Thermal UTCI\n",
    "output_vars['THERMAL_UTCI'] = thermal_utci_interp['utci']\n",
    "\n",
    "# ASTGTM Digital Elevation Model\n",
    "output_vars['ASTER_GDEM_DEM'] = astgtm_interp['ASTER_GDEM_DEM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\xcube\\lib\\site-packages\\xarray\\core\\indexing.py:1379: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "xr.Dataset(output_vars).chunk({'lon':50, 'lat':50}).to_zarr('datacube_linear_300.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xcube",
   "language": "python",
   "name": "xcube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
